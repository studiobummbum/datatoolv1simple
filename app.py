import streamlit as st
import pandas as pd
import io
import csv

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="AdMob Cohort Analyzer Pro", layout="wide")

st.title("üí∞ AdMob Cohort LTV Analyzer (V3.5 - Fix Tab Separator)")
st.markdown("""
<style>
    .stAlert { padding: 10px; border-radius: 5px; }
    .success { background-color: #d4edda; color: #155724; }
</style>
""", unsafe_allow_html=True)

st.info("üí° Upload file `admob-report.csv`. H·ªá th·ªëng t·ª± ƒë·ªông nh·∫≠n di·ªán header, encoding v√† d·∫•u ngƒÉn c√°ch.")

# --- H√ÄM X·ª¨ L√ù DATA ---
def load_data(uploaded_file):
    # Danh s√°ch encoding hay g·∫∑p
    encodings = ['utf-16', 'utf-8', 'latin1', 'cp1252'] # ƒê∆∞a utf-16 l√™n ƒë·∫ßu v√¨ file s·∫øp l√† utf-16
    # Danh s√°ch d·∫•u ngƒÉn c√°ch hay g·∫∑p (Tab ho·∫∑c Ph·∫©y)
    separators = ['\t', ','] 
    
    df = None
    used_encoding = None
    used_sep = None
    header_row = 0
    
    # Logic d√≤ t√¨m "tr√¢u b√≤" h∆°n: Th·ª≠ combo (Encoding + Separator + Skiprows)
    possible_skiprows = [0, 1, 2] 
    
    for enc in encodings:
        for sep in separators:
            for skip in possible_skiprows:
                try:
                    uploaded_file.seek(0)
                    # ƒê·ªçc th·ª≠ v√†i d√≤ng ƒë·ªÉ check
                    temp_df = pd.read_csv(uploaded_file, skiprows=skip, encoding=enc, sep=sep, on_bad_lines='skip', nrows=10)
                    
                    # N·∫øu ƒë·ªçc ra m√† ch·ªâ c√≥ 1 c·ªôt th√¨ kh·∫£ nƒÉng cao l√† sai separator -> B·ªè qua
                    if len(temp_df.columns) < 2:
                        continue

                    # Check xem t√™n c·ªôt c√≥ ch·ª©a t·ª´ kh√≥a quan tr·ªçng kh√¥ng
                    col_str = " ".join([str(c).lower() for c in temp_df.columns])
                    if ('date' in col_str or 'ng√†y' in col_str) and ('country' in col_str or 'install' in col_str):
                        # N·∫øu OK th√¨ ƒë·ªçc full file
                        uploaded_file.seek(0)
                        df = pd.read_csv(uploaded_file, skiprows=skip, encoding=enc, sep=sep, on_bad_lines='skip')
                        used_encoding = enc
                        used_sep = sep
                        header_row = skip
                        break
                except:
                    continue
            if df is not None: break
        if df is not None: break
            
    return df, used_encoding, used_sep, header_row

# --- UI CH√çNH ---
uploaded_file = st.file_uploader("üìÇ K√©o th·∫£ file CSV v√†o ƒë√¢y s·∫øp ∆°i", type=['csv', 'txt'])

if uploaded_file is not None:
    with st.spinner('ƒêang soi data c·ªßa s·∫øp...'):
        df, encoding, sep, header_row = load_data(uploaded_file)

    if df is None:
        st.error("‚ùå Em ch·ªãu thua! Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file. S·∫øp check l·∫°i xem c√≥ ph·∫£i CSV chu·∫©n kh√¥ng?")
        st.stop()

    # --- X·ª¨ L√ù T√äN C·ªòT (MAPPING) ---
    # Chu·∫©n h√≥a t√™n c·ªôt hi·ªán t·∫°i v·ªÅ ch·ªØ th∆∞·ªùng, b·ªè kho·∫£ng tr·∫Øng th·ª´a
    df.columns = df.columns.astype(str).str.strip()
    
    # Dictionary t·ª´ kh√≥a ƒë·ªÉ map
    mapping_rules = {
        'Date': ['install date', 'date', 'ng√†y'],
        'Country': ['install country', 'country', 'qu·ªëc gia', 'region'],
        'Day': ['days since install', 'day', 'ng√†y k·ªÉ t·ª´'],
        'LTV': ['ltv (usd)', 'ltv', 'revenue', 'doanh thu'], # ∆Øu ti√™n LTV (USD)
        'Installs': ['installs', 'l∆∞·ª£t c√†i ƒë·∫∑t', 'c√†i ƒë·∫∑t']
    }

    final_rename_map = {}
    found_cols = []

    # Logic t√¨m c·ªôt
    for target_name, keywords in mapping_rules.items():
        match_col = None
        for col in df.columns:
            col_lower = col.lower()
            if any(kw in col_lower for kw in keywords):
                # Logic lo·∫°i tr·ª´ ƒë·∫∑c bi·ªát
                if target_name == 'Installs' and ('date' in col_lower or 'day' in col_lower or 'country' in col_lower or 'ltv' in col_lower):
                    continue
                # N·∫øu t√¨m LTV, ∆∞u ti√™n c·ªôt t·ªïng LTV ch·ª© kh√¥ng ph·∫£i IAP LTV hay Ads LTV
                if target_name == 'LTV' and ('iap' in col_lower or 'ads' in col_lower or 'sub' in col_lower):
                    continue
                    
                match_col = col
                break
        
        if match_col:
            final_rename_map[match_col] = target_name
            found_cols.append(target_name)

    # --- HI·ªÇN TH·ªä TR·∫†NG TH√ÅI MAPPING (DEBUG) ---
    with st.expander("üïµÔ∏è‚Äç‚ôÇÔ∏è Debug: Th√¥ng s·ªë file (S·∫øp check nh√©)"):
        st.write(f"**Encoding:** `{encoding}` | **Separator:** `{repr(sep)}` | **Header Row:** `{header_row}`")
        st.write("**Mapping:**", final_rename_map)
        st.write("Data sau khi t√°ch c·ªôt:")
        st.dataframe(df.head())

    # Ki·ªÉm tra c·ªôt b·∫Øt bu·ªôc
    required_cols = ['Date', 'Day', 'LTV']
    missing = [col for col in required_cols if col not in found_cols]
    
    if missing:
        st.error(f"‚ùå Toang r·ªìi s·∫øp ∆°i! Em kh√¥ng t√¨m th·∫•y c·ªôt: {', '.join(missing)}. S·∫øp check l·∫°i ph·∫ßn Debug xem t√™n c·ªôt n√≥ nh·∫≠n l√† g√¨?")
        st.stop()

    # --- √ÅP D·ª§NG RENAME ---
    df = df.rename(columns=final_rename_map)

    # --- CLEAN DATA TYPES ---
    try:
        # 1. Date
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date
        df = df.dropna(subset=['Date'])

        # 2. LTV & Installs (X·ª≠ l√Ω d·∫•u ph·∫©y, d·∫•u $)
        cols_to_numeric = ['LTV']
        if 'Installs' in df.columns:
            cols_to_numeric.append('Installs')
        
        for col in cols_to_numeric:
            if df[col].dtype == object:
                df[col] = df[col].astype(str).str.replace(r'[$,‚Ç´a-zA-Z()]', '', regex=True)
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        
        if 'Installs' not in df.columns:
            df['Installs'] = 1 

    except Exception as e:
        st.error(f"‚ùå L·ªói khi clean data: {e}")
        st.stop()

    # --- PIVOT TABLE (COHORT) ---
    target_days = [0, 1, 3, 7, 14, 28, 30, 60]
    df_filtered = df[df['Day'].isin(target_days)].copy()

    if 'Country' not in df.columns:
        df_filtered['Country'] = 'Global'

    # L·∫•y Installs t·∫°i Day 0 l√†m g·ªëc
    df_installs = df[df['Day'] == 0][['Date', 'Country', 'Installs']].drop_duplicates()
    # N·∫øu 1 ng√†y c√≥ nhi·ªÅu d√≤ng c√πng country (hi·∫øm g·∫∑p nh∆∞ng c·ª© ƒë·ªÅ ph√≤ng), ta sum l·∫°i
    df_installs = df_installs.groupby(['Date', 'Country'], as_index=False)['Installs'].sum()
    
    # Pivot LTV
    df_ltv = df_filtered.pivot_table(
        index=['Date', 'Country'],
        columns='Day',
        values='LTV',
        aggfunc='sum'
    ).reset_index()
    
    # Merge Installs v√†o b·∫£ng LTV
    final_df = pd.merge(df_installs, df_ltv, on=['Date', 'Country'], how='left')
    
    # ƒê·ªïi t√™n c·ªôt
    new_cols = {d: f'LTV D{d}' for d in target_days if d in final_df.columns}
    final_df = final_df.rename(columns=new_cols)
    final_df = final_df.fillna(0)
    final_df = final_df.sort_values(by='Date', ascending=False)

    # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
    st.success("‚úÖ Ngon l√†nh r·ªìi s·∫øp ∆°i!")
    
    # Format hi·ªÉn th·ªã
    format_config = {'Installs': '{:,.0f}'}
    ltv_cols = [c for c in final_df.columns if 'LTV' in c]
    for c in ltv_cols:
        format_config[c] = '${:.4f}'

    st.dataframe(
        final_df.style.format(format_config)
        .background_gradient(cmap='Greens', subset=ltv_cols),
        use_container_width=True,
        height=600
    )